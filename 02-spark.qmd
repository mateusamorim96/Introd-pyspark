---
bibliography: references.bib
---

# Introducing Apache Spark

In essence, `pyspark` is an API to Apache Spark (or simply Spark). In other words, with `pyspark` we can write Spark applications using the python language. By learning a little more about Spark, you will understand a lot more about `pyspark`.

Spark is a multi-language engine for large-scale data processing in a single-node machine or in a cluster of machines. Nowadays, Spark became the de facto standard for structuring big data applications and workloads. It has a number of features that its predecessors did not have, like the capacity for in-memory processing and stream processing [@karau2015].


